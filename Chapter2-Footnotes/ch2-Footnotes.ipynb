{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter Two - Footnotes: The Poetics of Progress\n",
    "\n",
    "In this notebook, I walk through my steps in performing the [clustering](#Clustering) and [classification](#Classification) experiments found in chapter two. I've included pickled versions of the corpora I use in the tests. I've also included the metadata csv for the 18th-century progress poems I analyze in case you want to process the texts differently. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import bookFunctions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "### These are function files\n",
    "sys.path.insert(0, '/Users/collinjennings/dropbox/eccoDriveWork') ### Change this to match github directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpora\n",
    "\n",
    "Both experiments compare 55 progress poems to 55 randomly selected works from the 18th century. The random sample includes poetry and prose. I explain why this is the case at length in the book. Here I've stored the two collections in one pickle file for easy handling. The pickle is structured as a list of dictionaries that include the text, author, publication dates, and class of the works. For more bibliographical details, see the metadata csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corpus = pickle.load(open('progressPlusSample.p', 'rb'))\n",
    "full_text = [' '.join(item['text']) for item in full_corpus]\n",
    "corpus_sample = full_corpus[54:]\n",
    "print (len(full_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the metadata into lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists make it a bit easier to create a dataframe for analyzing and visualizing the differences between the two corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDividingLine = 54 ### End of \n",
    "classes = [] \n",
    "authors = [] \n",
    "titles = [] \n",
    "dates =[] \n",
    "for idx, item in enumerate(full_corpus): \n",
    "    if idx < classDividingLine: \n",
    "        classes.append('poetry')\n",
    "        authors.append(item['author'][:20])\n",
    "        titles.append(item['title']) \n",
    "        dates.append(int(item['date']))\n",
    "    else: \n",
    "        classes.append(item['class'])\n",
    "        authors.append(item['author'][:20])\n",
    "        titles.append(item['title']) \n",
    "        dates.append(int(item['date']))\n",
    "        \n",
    "### Shorten the titles for visualizing.\n",
    "titles3 = [title[:20] for title in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the text wordlists into vectors for cluster visualization\n",
    "This version of the experiment limits the terms in the vocabulary to the top 400 bigrams that appear in a least 20% of the poems. The goal is to observe the differences in how the classes of poems use common phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='content', decode_error='replace', ngram_range=(2,2), stop_words=None,\n",
    "                             max_features=400, min_df=.20, norm='l2', use_idf=True)\n",
    "dtm = vectorizer.fit_transform(full_text)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dtm = dtm.toarray()\n",
    "dist = 1 - cosine_similarity(dtm)\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(dist)\n",
    "pos = pca.transform(dist)\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=titles3, class2=classes)) \n",
    "groups = df.groupby('class2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `idList` filters the labels to make the graph more legible. You can change which labels are included on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idList = [ 3, 11, 14,19, 20, 22, 38, 39, 56, 75, 68, 87, \n",
    "          93, 98, 81, 85, 102, 48, 103, 108, 110, 111, 38, 114, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Poems\n",
    "Here we visualize how the poetry poems cluster in relation to the texts from the sample corpus. There are a lot of ways you can tinker with the visualization. See the documentation for `matplotlib`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {'poetry': '#EBEBEB', 'sample': '#BBBABA'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12)) # set size\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=24, \n",
    "            label=name, color=cluster_colors[name]) \n",
    "\n",
    "for i in range(len(df)):\n",
    "    if i in idList: \n",
    "        ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['label'], horizontalalignment='left', size=11, weight='bold') \n",
    "ax.legend()\n",
    "plt.title('Semantic Proximity between Progress Poetry and ECCO Sample - Top 400 Bigrams', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the most informative bigrams\n",
    "\n",
    "This is a simple way to observe similarities and differences between clusters of poems in the graph. Update the x-axis and y-axis values as well as the `above` and `toTheLeft` boolean values. You are saying whether you want to examine the data points to the left of the x-value or not and the above the y-value or not. The `graph_analyzer` functions will return the words or phrases that have the highest frequency among the texts that appear within the area of focus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValue = None  \n",
    "yValue = None\n",
    "above = None ## defaults to True\n",
    "toTheLeft = None ## defaults to True\n",
    "\n",
    "posGroup, notGroup = graph_analyzer.separator(pos, xValue, , above=True, toTheLeft=True )\n",
    "avgArray, notAvgArray = graph_analyzer.analyzer(dtm2, posGroup, notGroup)\n",
    "allProg, nonProg = graph_analyzer.valueRanker(graph_analyzer.differencer\n",
    "                                                             (avgArray, notAvgArray),  vocab, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(upperProg, key=lambda x:x[1], reverse=True))\n",
    "print()\n",
    "print(sorted(nonUpProg, key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize the corpus for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sample = full_corpus[54:]\n",
    "progressCorpus = full_corpus[:54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progressTexts = textFieldCorpus(progressCorpus, 'text', 'progress') #, estcPhil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progressWordLabels = nonParsing('progress', progressTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampGroup = sampleProcessor(corpus_sample, 'text', 70)\n",
    "sampWordLabels = nonParsing('sample', sampGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, chunkLabels = buildCorpus(progressWordLabels, sampWordLabels, text_split, 300)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with the text chunks and their class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'category': chunkLabels, 'text': chunks}\n",
    "dfFull = pd.DataFrame(d)\n",
    "dfFull['category_id'] = dfFull['category'].factorize()[0]\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,2), min_df=.1, norm='l2', use_idf=False)\n",
    "                    \n",
    "feats = tfidf.fit_transform(dfFull.text).toarray()\n",
    "vocabulary = tfidf.get_feature_names()\n",
    "labels = dfFull.category_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier and compare the results of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, multi_class='ovr', solver='liblinear',),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, feats, labels, scoring='accuracy', cv=CV) \n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the model to use\n",
    "Specify the model by indexing the one you want from the block above. Linear SVC tends to perform the best across the experiments of the book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = models[1]\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(feats, labels, dfFull.index, \n",
    "                                                                                 test_size=0.20, random_state=0)\n",
    "mod.fit(X_train, y_train)\n",
    "y_pred = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the classifier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names=dfFull['category'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for all other models\n",
    "modTerms = mostInformTerms(mod, topn=30)\n",
    "dfTM = docTermMatrix (feats, tfidf)\n",
    "suppMeanDF, sampMeanDF = bookFunctions.buildMeanDF(dfTM, feats, 'progress', chunkLabels)\n",
    "progWords, sampWords = bookFunctions.topGroupWord (suppMeanDF, sampMeanDF, modTerms, vocabulary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
